import cv2
import os
import face_recognition

def recognize_face_login():
    known_encodings = []
    known_names = []

    Saved_image_path_folder = "C:/Users/dhars/Downloads/Dhass/codeing/GUVI/2. MainBoot/4.Project_Code/Final Project - 1/Project6_Code/Intelliguard_PPE_Detection/4_authentication/face_Recognition/known_faces_images"
    print("\n Face Registered Root Folder Path:", Saved_image_path_folder)

    for person in os.listdir(Saved_image_path_folder):
        print(person)
        person_folder = os.path.join(Saved_image_path_folder, person)
        print(person_folder)
        for file in os.listdir(person_folder):
            print(file)
            image_path = os.path.join(person_folder, file)
            print(image_path)
            img = face_recognition.load_image_file(image_path)
            print(img)
            encodings = face_recognition.face_encodings(img)
            print("Type of Encoding: ",type(encodings))
            

            if encodings:
                known_encodings.append(encodings[0])
                known_names.append(person)

    cap = cv2.VideoCapture(0)
    print("üé• Looking for a known face...")

    max_attempts = 100  # ‚è±Ô∏è Max number of frames to check
    attempts = 0

    while attempts < max_attempts:
        print("attempt:",attempts )
        print("max_attempts:", max_attempts )
        ret, frame = cap.read()
        print("Frame has read:",ret)
        
        if ret:
            print("‚úÖ Frame read successfully!")
        else:
            print("‚ùå Failed to read frame from webcam.")


        # print(frame)
        if not ret:
            break

        attempts += 1
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        # small_frame = cv2.resize(rgb_frame, (0, 0), fx=0.25, fy=0.25)

        face_locations = face_recognition.face_locations(rgb_frame)
        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

        for face_encoding in face_encodings:
            matches = face_recognition.compare_faces(known_encodings, face_encoding)
            name = "Unknown"

            if True in matches:
                matched_idx = matches.index(True)
                name = known_names[matched_idx]
                print(f"‚úÖ Face authenticated: {name}")
                cap.release()
                cv2.destroyAllWindows()
                return name, frame  # Return the authenticated name and frame

        cv2.imshow('Video', frame)
        if cv2.waitKey(1) == ord('q'):
            break

    # If we exit the loop without a match
    cap.release()
    cv2.destroyAllWindows()
    print("‚ùå Face not recognized after several attempts.")
    return None, None

# Optional standalone test
if __name__ == "__main__":
    recognize_face_login()
    # return recognize_face_login()
















#Face Login/ Recognition:
# def load_known_faces():
#   known_encodings = []
#   known_names = []
    
#   for person in os.listdir("known_faces_images"):
#     # print(person)

#     # print(os.path.join("known_faces_images"))
#     person_folder = os.path.join("known_faces_images", person)
#     # print(person_folder)

#     for file in os.listdir(person_folder):
#         # print(file)

#         image_path = os.path.join(person_folder, file)
#         # print(image_path)

#         img = face_recognition.load_image_file(image_path)
#         # print(img) #Pixel at (0, 0): R=147, G=161, B=128       #Each pixel contains 3 values for RGB channels:     [R, G, B] ‚Üí Red, Green, Blue values (each from 0 to 255)

#         # print(type(img))         # <class 'numpy.ndarray'>
#         # print(img.shape)         # e.g., (480, 640, 3)
#         # print(img[0, 0])         # [147 161 128] ‚Üí RGB of top-left pixel

#         encodings = face_recognition.face_encodings(img)
#         # print(type(encodings))
#         # print(encodings)
#         #It is a list of 128-dimensional face encodings ‚Äî that is:    [array([... 128 float values ...])]

#         # What does each encoding represent?
#         #         Each encoding is a numerical fingerprint of a face.
#         #         It‚Äôs a vector with 128 floating-point numbers.
#         #         Generated by a deep learning model (built on top of dlib). 
#         #         Represents key facial features, such as: Eye distance,Nose shape,Jawline,Mouth width, etc.

#         # print(type(encodings[0])) #<class 'numpy.ndarray'> Confirms the data type              #print(repr(encodings[0]))	array([ ... ])	Full array representation
#         # print(encodings[0]) #[... 128 float values ...]  #Just values (no array label)

#         if encodings:
#                 known_encodings.append(encodings[0])
#                 known_names.append(person)
                
#     return known_encodings, known_names

# known_encodings, known_names = load_known_faces()

# cap = cv2.VideoCapture(0) # initializes the default webcam (device index 0) for video capture.
# # print(cap)
# print("üé• Looking for a known face...")




# authenticated = False

# while True:
#     ret, frame = cap.read() #cap.read() -> tries to grab a single frame from the webcam
#     #ret: a boolean ‚Äî True if the frame was read successfully, False otherwise.
#     # frame: the actual image frame (as a NumPy array) or None if it failed.


#     # print(ret,frame)    #O/p:      #  True           False -> webcam is not open  
#     #  [[[ 4  2  5]        #NumPy array with shape (height, width, 3). 3 cahnnel -> [ 4  2  5] BGR 
#     #    [ 4  2  5]
#     #    [ 4  2  5]
#     #    ...
#     #    [63 68 56]
#     #    [63 68 56]
#     #    [63 68 56]]]

#     #if its false (webcam doesn't open), the loop will run continuously, so break
#     if not ret:
#         break
    
#     rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #opencv will open the image in bgr. so converting to rgb
#     # print(rgb) #NumPy array representing the frame in RGB format. with shape (height, width, 3)

#     faces = face_recognition.face_locations(rgb)
#     # print(faces) #This function detects all faces present in the current video frame (rgb image). 
#     #It returns a list of bounding boxes, one for each face it detects. [(100, 250, 200, 150)]
#     # If no face is found, then empty list -> []

#     # This means:
#         # top = 100 ‚Üí the y-coordinate of the top edge
#         # right = 250 ‚Üí the x-coordinate of the right edge
#         # bottom = 200 ‚Üí the y-coordinate of the bottom edge
#         # left = 150 ‚Üí the x-coordinate of the left edge

#     # So this bounding box spans:
#         # Width: 250 - 150 = 100 pixels
#         # Height: 200 - 100 = 100 pixels
#     encodings = face_recognition.face_encodings(rgb, faces) 
#     # print(encodings) #[array([-1.64310098e-01,  2.14287937e-02,  4.34486344e-02, -1.48049118e-02,-1.02237649e-01])]
#     # It generates a 128-dimensional feature vector (float array) for each face.
#     #Each encoding is a NumPy array
    

#     for encoding in encodings:
#         # print(encoding) #[-1.38567150e-01  3.49037647e-02  7.58042037e-02 -1.31625682e-02]
#         matches = face_recognition.compare_faces(known_encodings, encoding)
#         # print(matches) #[True]
#         if True in matches:
#             match_idx = matches.index(True)
#             # print(match_idx) #0
#             name = known_names[match_idx]  #known_names[0] #Dharshini
#             print(f"‚úÖ Face authenticated: {name}")
#             authenticated = True
#             break

#     cv2.imshow("Face Login", frame)
#     if cv2.waitKey(1) == ord('q') or authenticated: #Exit the loop if either of these two conditions is true       waits for 1 millisecond for a keypress
#         break

# cap.release() #Releases the webcam. This frees up the hardware so other programs can access the camera later.
# cv2.destroyAllWindows() #Closes all OpenCV windows that were opened with cv2.imshow()

# if not authenticated:
#     print("‚ùå Face not recognized.")